{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with Gensim\n",
    "\n",
    "This is a simple worked example for training and interpreting a topic model with [Gensim](https://radimrehurek.com/gensim). It assumes that the input text has already been cleaned and processed. For a more in-depth example that also includes using [Spacy](https://spacy.io) for text cleaning, see Patrick Harrison's [Modern NLP in Python](https://www.youtube.com/watch?v=6zm9NC9uRkk) talk and accompanying [notebook](https://github.com/skipgram/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "\n",
    "# this file should contain a collection of documents, one per line,\n",
    "# with each document being represented as whitespace-separated tokens\n",
    "TEXT_FILE_PATH = \"cleaned_text.txt\"\n",
    "\n",
    "# The number of worker processes to use for parallel computing. A good number \n",
    "# is N-1, where N is the number of actual CPU cores you have (not hyperthreads). \n",
    "# You might need to set this to 1 on Windows.\n",
    "WORKERS = 3\n",
    "\n",
    "def tokens_from_file(path):\n",
    "    \"\"\"Generator yielding tokens for each document in a file.\n",
    "    Assumes input file has one document per line with tokens separated \n",
    "    by whitespace. \n",
    "    \"\"\"\n",
    "    with open(path) as file:\n",
    "        for line in file:\n",
    "            yield line.strip().split()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to build a dictionary from the cleaned text. As part of this process we filter out tokens that are very rare or too common from the corpus. With these settings, a token must occur at least 10 times to be kept, and it will be filtered out if it occurs in more than 40% of documents. See [Gensim's documentation](https://radimrehurek.com/gensim/corpora/dictionary.html) for other parameters to the `filter_extremes` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(tokens_from_file(TEXT_FILE_PATH))\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.4)\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to use the trained dictionary model to convert the corpus into a sequence of bag of words, before we can train the LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_texts = [dictionary.doc2bow(tokens) for tokens in tokens_from_file(TEXT_FILE_PATH)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the LDA model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(\n",
    "    bow_texts,\n",
    "    num_topics=15,\n",
    "    id2word=dictionary,\n",
    "    workers=WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a helper function to explore the top terms for each topic. Have a look at a few different topics and see if you can identify a coherent theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "-d-                  0.112\n",
      "-dd-                 0.045\n",
      "line                 0.014\n",
      "b                    0.013\n",
      "minister             0.013\n",
      "amendment            0.011\n",
      "schedule             0.011\n",
      "-month-_-year-       0.008\n",
      "page_-dd-            0.007\n",
      "c                    0.007\n",
      "year                 0.007\n",
      "government           0.007\n",
      "-ddd-                0.007\n",
      "subsection           0.006\n",
      "item                 0.006\n",
      "substitute           0.006\n",
      "question             0.005\n",
      "page                 0.005\n",
      "minute               0.005\n",
      "person               0.005\n",
      "-month-              0.005\n",
      "leave_grant          0.004\n",
      "notice               0.004\n",
      "project              0.004\n",
      "item_-dd-            0.004\n"
     ]
    }
   ],
   "source": [
    "def explore_topic(model, topic_number, topn=20):\n",
    "    \"\"\"Accept a user-supplied topic number and\n",
    "    print out a formatted list of the top terms\n",
    "    \"\"\"\n",
    "    print(f\"{'term':20} frequency\\n\")\n",
    "    for term, frequency in model.show_topic(topic_number, topn=25):\n",
    "        print(f\"{term:20} {frequency:.3f}\")\n",
    "\n",
    "explore_topic(lda, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While looking at the top key words is useful, an even better approach is the [pyLDAvis](https://github.com/bmabey/pyLDAvis) tool. Note that this can take a while to run due to the dimensionality reduction it has to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldavis_prepared = pyLDAvis.gensim.prepare(lda, bow_texts, dictionary, n_jobs=WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldavis_prepared.display(LDAvis_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
